{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f4ac77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "imagem \n",
      "\n",
      "Temos a seguinte classe que representa um usuário no nosso sistema:\n",
      "\n",
      "java\n",
      "\n",
      "Para salvar um novo usuário, várias validações são feitas, como por exemplo: Ver se o nome só contém letras, [**o CPF só números**] e ver se o usuário possui no mínimo 18 anos. Veja o método que faz essa validação:\n",
      "\n",
      "java \n",
      "\n",
      "Suponha agora que eu tenha outra classe, a classe `Produto`, que contém um atributo nome e eu quero fazer a mesma validação que fiz para o nome do usuário: Ver se só contém letras. E aí? Vou\n"
     ]
    }
   ],
   "source": [
    "with open(\"dados/artigos.txt\", \"r\", encoding = 'utf8') as f:\n",
    "    artigos = f.read()\n",
    "    \n",
    "print(artigos[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8b5b2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2605046"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(artigos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53ce21cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "texto_exemplo = \"Olá, tudo bem?\"\n",
    "tokens = texto_exemplo.split()\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16825d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\python310\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: joblib in c:\\python310\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\python310\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\python310\\lib\\site-packages (from nltk) (2022.6.2)\n",
      "Requirement already satisfied: click in c:\\python310\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\evers\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip3 install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "palavras_separadas = nltk.tokenize.word_tokenize(texto_exemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acf4eb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Olá', ',', 'tudo', 'bem', '?']\n"
     ]
    }
   ],
   "source": [
    "print(palavras_separadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c158245b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(palavras_separadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54b0fe7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olá', 'tudo', 'bem']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def separa_palavras(lista_tokens):\n",
    "    lista_palavras = []\n",
    "    for token in lista_tokens:\n",
    "        if token.isalpha():\n",
    "            lista_palavras.append(token)\n",
    "    return lista_palavras\n",
    "\n",
    "separa_palavras(palavras_separadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "088543a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O número de palavras é 403031\n"
     ]
    }
   ],
   "source": [
    "lista_tokens = nltk.tokenize.word_tokenize(artigos)\n",
    "lista_palavras = separa_palavras(lista_tokens)\n",
    "print(f\" O número de palavras é {len(lista_palavras)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "066af2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagem', 'temos', 'a', 'seguinte', 'classe']\n"
     ]
    }
   ],
   "source": [
    "def normalizacao(lista_palavras):\n",
    "    lista_normalizada = []\n",
    "    for palavra in lista_palavras:\n",
    "        lista_normalizada.append(palavra.lower())\n",
    "    return lista_normalizada\n",
    "\n",
    "lista_normalizada = normalizacao(lista_palavras)\n",
    "print(lista_normalizada[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6ed29d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18464"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(lista_normalizada))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d35d82",
   "metadata": {},
   "source": [
    "##### O algoritmo funcionará separando as palavras em (Esqueda + letra + Direita) isso vai ser percorrido por toda palavra, gerando possíveis candidatas à correção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e1c39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "443f2bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 'lgica'), ('l', 'gica'), ('lg', 'ica'), ('lgi', 'ca'), ('lgic', 'a'), ('lgica', '')]\n"
     ]
    }
   ],
   "source": [
    "palavra_exemplo = 'lgica'\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra)+1):\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    return palavras_geradas\n",
    "    \n",
    "gerador_palavras(palavra_exemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f83ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insere_letras(fatias):\n",
    "    \n",
    "    return novas_palavras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
